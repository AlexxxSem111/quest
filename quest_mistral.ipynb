{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 5112,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 3900
        },
        {
          "sourceId": 10942,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 8846
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexxxSem111/quest/blob/main/quest_mistral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "GeeJHuLovoAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "step_count = 0\n",
        "user_count = 0\n",
        "binary_steps = [0, 1, 3]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:36:02.139715Z",
          "iopub.execute_input": "2024-02-19T11:36:02.140063Z",
          "iopub.status.idle": "2024-02-19T11:36:02.145113Z",
          "shell.execute_reply.started": "2024-02-19T11:36:02.140039Z",
          "shell.execute_reply": "2024-02-19T11:36:02.144181Z"
        },
        "trusted": true,
        "id": "R_EsyC2KRx8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Данные для логики квеста\n",
        "Их немного у меня поэтому оставил так.\n",
        "Здесь нет суммаризации прошлых ответов но их не трудно добавить, просто думаю это уже у вас реализовано как то по другому.\n",
        "\n",
        "Они содержат номер Шага, варианты запроса для Шага, варианты следующего Шага и возможна ли пользовательская Игра на Шаге.\n",
        "Колонка 'Action' содержит дополнительные инструкции к промпту.\n",
        "\n",
        "Ход этого квеста:\n",
        "- Шаг 0 - должно быть(в деплое) приветствие с вопросом \"хотите пройти квест?\" и первый запрос это ответ на этот вопрос.\n",
        "- Шаг 1 - короткая история с вопросом \"хотите продолжить?\"\n",
        "- Шаг 2 - история в которой есть развилка и нужно выбрать куда пойти. (кластеризацию запроса для этого шага я пока не делал)\n",
        "    чтобы протестировать нужно, чтобы запрос обязательно содержал одно из этих 3 слов:\n",
        "    - 'right' - 1 вариант истории.\n",
        "    - 'left' - 2 вариант истории.\n",
        "    - 'any' - свой вариант, история меняется Шаг остается 2, после нескольких своих вариантов Шаг автоматически увеличится.\n",
        "- Шаг 3 - история с вопросом \"что дальше?\" в зависимости от ответа вариант истории и сброс на 0."
      ],
      "metadata": {
        "id": "ThjDA_4NRx8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = [{'Step': 0,\n",
        "  'Variant': 'POS',\n",
        "  'Action': 'Tell a short 4-5 sentence fairy tale about a bear. Finish story with variant of question \"Do you want to continue?\".',\n",
        "  'ToStep': 1,\n",
        "  'UserGame': False},\n",
        " {'Step': 0,\n",
        "  'Variant': 'NEG',\n",
        "  'Action': 'Say something with variant of \"Thank you, goodbye\".',\n",
        "  'ToStep': 0,\n",
        "  'UserGame': False},\n",
        " {'Step': 1,\n",
        "  'Variant': 'POS',\n",
        "  'Action': 'Tell a short 4-5 sentence fairy tale about a bear at the fork of road. Finish story with variant of question \"Which way?\".',\n",
        "  'ToStep': 2,\n",
        "  'UserGame': False},\n",
        " {'Step': 1,\n",
        "  'Variant': 'NEG',\n",
        "  'Action': 'Tell a short 1-2 sentence fairy tale about a bear dying. Finish story with variant of question \"Do you want to try again?\".',\n",
        "  'ToStep': 0,\n",
        "  'UserGame': False},\n",
        " {'Step': 2,\n",
        "  'Variant': 'Right',\n",
        "  'Action': 'Tell a short 4-5 sentence fairy tale about a bear visit a rabbit. Finish story with variant of question \"What s next?\"',\n",
        "  'ToStep': 3,\n",
        "  'UserGame': False},\n",
        " {'Step': 2,\n",
        "  'Variant': 'Left',\n",
        "  'Action': 'Tell a short 2-3 sentence fairy tale about a bear dying. Finish story with variant of question \"Do you want to try again?\".',\n",
        "  'ToStep': 0,\n",
        "  'UserGame': False},\n",
        " {'Step': 2,\n",
        "  'Variant': 'Any',\n",
        "  'Action': 'Tell a short 7-8 sentence fairy tale about a bear at fork of road. Finish story with variant of question \"Which way?\".',\n",
        "  'ToStep': 2,\n",
        "  'UserGame': True},\n",
        " {'Step': 3,\n",
        "  'Variant': 'POS',\n",
        "  'Action': 'Tell a short 4-5 sentence fairy tale about a bear with happy end. Finish story with congratulations.',\n",
        "  'ToStep': 0,\n",
        "  'UserGame': False},\n",
        " {'Step': 3,\n",
        "  'Variant': 'NEG',\n",
        "  'Action': 'Tell a short 2-3 sentence fairy tale about a bear with bad end. Finish story with congratulations.',\n",
        "  'ToStep': 0,\n",
        "  'UserGame': False}]\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:36:04.578547Z",
          "iopub.execute_input": "2024-02-19T11:36:04.578908Z",
          "iopub.status.idle": "2024-02-19T11:36:04.600541Z",
          "shell.execute_reply.started": "2024-02-19T11:36:04.578882Z",
          "shell.execute_reply": "2024-02-19T11:36:04.59956Z"
        },
        "trusted": true,
        "id": "qQVJ_IfuRx8O",
        "outputId": "96c22039-ac82-4506-d7a6-34d6856129b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 7,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Step Variant                                             Action  ToStep  \\\n0     0     POS  Tell a short 4-5 sentence fairy tale about a b...       1   \n1     0     NEG  Say something with variant of \"Thank you, good...       0   \n2     1     POS  Tell a short 4-5 sentence fairy tale about a b...       2   \n3     1     NEG  Tell a short 1-2 sentence fairy tale about a b...       0   \n4     2   Right  Tell a short 4-5 sentence fairy tale about a b...       3   \n5     2    Left  Tell a short 2-3 sentence fairy tale about a b...       0   \n6     2     Any  Tell a short 7-8 sentence fairy tale about a b...       2   \n7     3     POS  Tell a short 4-5 sentence fairy tale about a b...       0   \n8     3     NEG  Tell a short 2-3 sentence fairy tale about a b...       0   \n\n   UserGame  \n0     False  \n1     False  \n2     False  \n3     False  \n4     False  \n5     False  \n6      True  \n7     False  \n8     False  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Step</th>\n      <th>Variant</th>\n      <th>Action</th>\n      <th>ToStep</th>\n      <th>UserGame</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>POS</td>\n      <td>Tell a short 4-5 sentence fairy tale about a b...</td>\n      <td>1</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>NEG</td>\n      <td>Say something with variant of \"Thank you, good...</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>POS</td>\n      <td>Tell a short 4-5 sentence fairy tale about a b...</td>\n      <td>2</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>NEG</td>\n      <td>Tell a short 1-2 sentence fairy tale about a b...</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Right</td>\n      <td>Tell a short 4-5 sentence fairy tale about a b...</td>\n      <td>3</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2</td>\n      <td>Left</td>\n      <td>Tell a short 2-3 sentence fairy tale about a b...</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2</td>\n      <td>Any</td>\n      <td>Tell a short 7-8 sentence fairy tale about a b...</td>\n      <td>2</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3</td>\n      <td>POS</td>\n      <td>Tell a short 4-5 sentence fairy tale about a b...</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3</td>\n      <td>NEG</td>\n      <td>Tell a short 2-3 sentence fairy tale about a b...</td>\n      <td>0</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Модель для sentiment-analysis\n",
        "Натренирована мной на 4000 комментариях из отзывов IMBD, выложена на HuggingFace.\n",
        "\n",
        "В binary_steps шагах определяет: положительный или отрицательный запрос."
      ],
      "metadata": {
        "id": "IHtM3nZwRx8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    pipeline,\n",
        "    DistilBertForSequenceClassification,\n",
        "    DistilBertTokenizerFast\n",
        ")\n",
        "\n",
        "sentiment_model_path = 'AlexxxSem/distilbert-yes-no'\n",
        "\n",
        "sentiment_model = DistilBertForSequenceClassification.from_pretrained(sentiment_model_path)\n",
        "sentiment_tokenizer = DistilBertTokenizerFast.from_pretrained(sentiment_model_path)\n",
        "\n",
        "sentiment = pipeline(\"sentiment-analysis\",\n",
        "                     model=sentiment_model,\n",
        "                     tokenizer=sentiment_tokenizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:33:30.060404Z",
          "iopub.execute_input": "2024-02-19T11:33:30.060791Z",
          "iopub.status.idle": "2024-02-19T11:33:37.828873Z",
          "shell.execute_reply.started": "2024-02-19T11:33:30.060757Z",
          "shell.execute_reply": "2024-02-19T11:33:37.827858Z"
        },
        "trusted": true,
        "id": "5e6vE4iDRx8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция обработки квеста и модификации запроса"
      ],
      "metadata": {
        "id": "sABuf7QJRx8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_query(query, df):\n",
        "    global step_count\n",
        "    global user_count\n",
        "\n",
        "    # Фильтруем DataFrame по текущему step_count\n",
        "    step_df = df[df['Step'] == step_count]\n",
        "\n",
        "    if step_count in binary_steps:\n",
        "        # Определяем 'sentiment' запроса\n",
        "        desired_value = sentiment(query)[0]['label']\n",
        "\n",
        "        # Выбираем строку, где 'Variant' равен 'sentiment'\n",
        "        selected_row = step_df[step_df['Variant'] == desired_value]\n",
        "\n",
        "        # Получаем значение (Action, ToStep, UserGame)\n",
        "        action = selected_row['Action'].values[0]\n",
        "        to_step = selected_row['ToStep'].values[0]\n",
        "        user_game = selected_row['UserGame'].values[0]\n",
        "\n",
        "    else:\n",
        "        # Получаем уникальные варианты для данного шага\n",
        "        variants = step_df['Variant'].unique()\n",
        "\n",
        "        for variant in variants:\n",
        "            if variant.lower() in query.lower():\n",
        "                # Получаем значение (Action, ToStep, UserGame) для варианта\n",
        "                action = step_df[step_df['Variant'] == variant]['Action'].values[0]\n",
        "                to_step = step_df[step_df['Variant'] == variant]['ToStep'].values[0]\n",
        "                user_game = step_df[step_df['Variant'] == variant]['UserGame'].values[0]\n",
        "\n",
        "    # Изменяем запрос\n",
        "    instruction = ' Use following instruction: '\n",
        "\n",
        "    query = action + instruction + query\n",
        "\n",
        "    # Меняем шаг\n",
        "    step_count = to_step\n",
        "\n",
        "    # Обработка UserGame\n",
        "    if user_count == 2 and to_step == step_count:\n",
        "        user_count = 0\n",
        "        step_count += 1\n",
        "    elif user_count != 0 and to_step != step_count:\n",
        "        user_count = 0\n",
        "\n",
        "    if user_game:\n",
        "        user_count +=1\n",
        "\n",
        "    return query"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:36:12.834524Z",
          "iopub.execute_input": "2024-02-19T11:36:12.835307Z",
          "iopub.status.idle": "2024-02-19T11:36:12.845247Z",
          "shell.execute_reply.started": "2024-02-19T11:36:12.835276Z",
          "shell.execute_reply": "2024-02-19T11:36:12.844232Z"
        },
        "trusted": true,
        "id": "FN2NSYojRx8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Основная модель"
      ],
      "metadata": {
        "id": "abiurHBpRx81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes accelerate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:33:09.687651Z",
          "iopub.execute_input": "2024-02-19T11:33:09.688013Z",
          "iopub.status.idle": "2024-02-19T11:33:21.868253Z",
          "shell.execute_reply.started": "2024-02-19T11:33:09.687982Z",
          "shell.execute_reply": "2024-02-19T11:33:21.867192Z"
        },
        "trusted": true,
        "id": "QbSRSNQ6Rx82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    BitsAndBytesConfig,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:33:46.45824Z",
          "iopub.execute_input": "2024-02-19T11:33:46.459267Z",
          "iopub.status.idle": "2024-02-19T11:33:46.463988Z",
          "shell.execute_reply.started": "2024-02-19T11:33:46.459231Z",
          "shell.execute_reply": "2024-02-19T11:33:46.462877Z"
        },
        "trusted": true,
        "id": "BZLvfBGuRx84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Настройки для работы в Colab"
      ],
      "metadata": {
        "id": "7m7ia9JhRx85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:33:49.62823Z",
          "iopub.execute_input": "2024-02-19T11:33:49.628882Z",
          "iopub.status.idle": "2024-02-19T11:33:49.634832Z",
          "shell.execute_reply.started": "2024-02-19T11:33:49.628851Z",
          "shell.execute_reply": "2024-02-19T11:33:49.633886Z"
        },
        "trusted": true,
        "id": "JoQKpCCFRx9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:33:52.694029Z",
          "iopub.execute_input": "2024-02-19T11:33:52.694776Z",
          "iopub.status.idle": "2024-02-19T11:35:53.948941Z",
          "shell.execute_reply.started": "2024-02-19T11:33:52.694746Z",
          "shell.execute_reply": "2024-02-19T11:35:53.947748Z"
        },
        "trusted": true,
        "id": "KtSGicyARx9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Декоратор"
      ],
      "metadata": {
        "id": "IJNJ4tgtRx9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_query_wrapper(func):\n",
        "    def wrapper(query):\n",
        "        modified_query = modify_query(query, df)\n",
        "        return func(modified_query)\n",
        "    return wrapper"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:36:27.286796Z",
          "iopub.execute_input": "2024-02-19T11:36:27.287537Z",
          "iopub.status.idle": "2024-02-19T11:36:27.292478Z",
          "shell.execute_reply.started": "2024-02-19T11:36:27.287493Z",
          "shell.execute_reply": "2024-02-19T11:36:27.291468Z"
        },
        "trusted": true,
        "id": "EyXp-2m_Rx9M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Функция запроса"
      ],
      "metadata": {
        "id": "-QgCP-DwRx9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "@modify_query_wrapper\n",
        "def generate_response(query):\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": query}\n",
        "    ]\n",
        "\n",
        "    input_encoding = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(input_encoding,\n",
        "                                   pad_token_id=tokenizer.eos_token_id,\n",
        "                                   max_new_tokens=1000,\n",
        "                                   do_sample=True)\n",
        "\n",
        "    decoded_response = tokenizer.batch_decode(generated_ids,\n",
        "                                              skip_special_tokens=True)\n",
        "\n",
        "    #decoded_result = re.sub(r'\\[INST\\].*?\\[/INST\\] ', '', decoded_response[0])\n",
        "    decoded_result = decoded_response[0].replace(\"[INST]\", \"Query:\\n\\n\").replace(\"[/INST]\", \"\\n\\nStory:\\n\\n\")\n",
        "\n",
        "    return decoded_result"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:36:30.227186Z",
          "iopub.execute_input": "2024-02-19T11:36:30.227943Z",
          "iopub.status.idle": "2024-02-19T11:36:30.234197Z",
          "shell.execute_reply.started": "2024-02-19T11:36:30.227912Z",
          "shell.execute_reply": "2024-02-19T11:36:30.233176Z"
        },
        "trusted": true,
        "id": "9iY6PXZcRx9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование"
      ],
      "metadata": {
        "id": "qPnXCFkDRx9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Для быстрого сброса)\n",
        "step_count = 0\n",
        "user_count = 0"
      ],
      "metadata": {
        "trusted": true,
        "id": "3nCChoIiRx9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(step_count)\n",
        "print(user_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:43:17.910437Z",
          "iopub.execute_input": "2024-02-19T11:43:17.911296Z",
          "iopub.status.idle": "2024-02-19T11:43:17.915461Z",
          "shell.execute_reply.started": "2024-02-19T11:43:17.911262Z",
          "shell.execute_reply": "2024-02-19T11:43:17.914574Z"
        },
        "trusted": true,
        "id": "nV1vpdG1Rx93",
        "outputId": "9c25ce20-44a3-4134-f40b-499cb34e3a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "0\n1\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = \"go\"\n",
        "\n",
        "print(generate_response(message))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-19T11:42:58.012379Z",
          "iopub.execute_input": "2024-02-19T11:42:58.012765Z",
          "iopub.status.idle": "2024-02-19T11:43:04.704217Z",
          "shell.execute_reply.started": "2024-02-19T11:42:58.012735Z",
          "shell.execute_reply": "2024-02-19T11:43:04.703121Z"
        },
        "trusted": true,
        "id": "_jRn_oKXRx95",
        "outputId": "c7d8f575-85cb-4e1e-9380-4ec566a947fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Query:\n\n Tell a short 2-3 sentence fairy tale about a bear with bad end. Finish story with congratulations. Use following instruction: any \n\nStory:\n\n Once upon a time, there was a bear who lived happily in the forest, but as time went by, he grew tired of his simple life and yearned for more. He made his way to a nearby town, where he was met with cheers and applause, but eventually, the bear's greed and power-hunger consumed him, and he turned into a cruel and ruthless leader. Congratulations on finishing the fairy tale!\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Красивое тестирование\n",
        "У меня почему то сразу уменьшается время бесплатного GPU в Colab"
      ],
      "metadata": {
        "id": "YJNMueUmRx96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio"
      ],
      "metadata": {
        "id": "bRLQ-QQdRx-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def response(message, history):\n",
        "    return generate_response(message)\n",
        "\n",
        "gr.ChatInterface(response, title='Do you want play Quest?').launch()"
      ],
      "metadata": {
        "id": "uduar6piRx-H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}