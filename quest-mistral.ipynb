{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Модели"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:19:29.383080Z","iopub.status.busy":"2024-02-24T19:19:29.382105Z","iopub.status.idle":"2024-02-24T19:19:46.468638Z","shell.execute_reply":"2024-02-24T19:19:46.467477Z","shell.execute_reply.started":"2024-02-24T19:19:29.383044Z"},"trusted":true},"outputs":[],"source":["%pip install -q -U bitsandbytes\n","#accelerate gradio datasets"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["## Основная модель Mistral 7B Instruct v0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:19:46.470766Z","iopub.status.busy":"2024-02-24T19:19:46.470493Z","iopub.status.idle":"2024-02-24T19:21:34.183983Z","shell.execute_reply":"2024-02-24T19:21:34.183186Z","shell.execute_reply.started":"2024-02-24T19:19:46.470738Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,                         \n",")\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n","    device_map=\"auto\",\n",")\n","\n","model_id = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n","#\n","\n","model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config)\n","tokenizer = AutoTokenizer.from_pretrained(model_id)"]},{"cell_type":"markdown","metadata":{},"source":["## Модель классификатор DistilBERT 12 Classes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:21:34.185490Z","iopub.status.busy":"2024-02-24T19:21:34.185052Z","iopub.status.idle":"2024-02-24T19:22:03.846036Z","shell.execute_reply":"2024-02-24T19:22:03.844962Z","shell.execute_reply.started":"2024-02-24T19:21:34.185464Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    pipeline,\n","    AutoModelForSequenceClassification,\n",")\n","\n","classification_model_id = 'AlexxxSem/distilbert-12-classes'\n","\n","classification_model = AutoModelForSequenceClassification.from_pretrained(classification_model_id)\n","classification_tokenizer = AutoTokenizer.from_pretrained(classification_model_id)\n","\n","classify = pipeline(\"text-classification\",\n","                    model=classification_model,\n","                    tokenizer=classification_tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["## Модель суммаризации DistilBart CNN 12 6 SamSum"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:27:02.171117Z","iopub.status.busy":"2024-02-24T19:27:02.170185Z","iopub.status.idle":"2024-02-24T19:28:11.624568Z","shell.execute_reply":"2024-02-24T19:28:11.623511Z","shell.execute_reply.started":"2024-02-24T19:27:02.171074Z"},"trusted":true},"outputs":[],"source":["from transformers import BartForConditionalGeneration\n","\n","summarization_model_id = 'philschmid/distilbart-cnn-12-6-samsum'\n","#sshleifer/distilbart-cnn-12-6\n","\n","summarization_model = BartForConditionalGeneration.from_pretrained(summarization_model_id)\n","summarization_tokenizer = AutoTokenizer.from_pretrained(summarization_model_id)\n","\n","summary = pipeline(\"summarization\",\n","                   model=summarization_model,\n","                   tokenizer=summarization_tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["# Данные квеста"]},{"cell_type":"markdown","metadata":{},"source":["## Датасет со сценарием и логикой квеста"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:28:21.895374Z","iopub.status.busy":"2024-02-24T19:28:21.894338Z","iopub.status.idle":"2024-02-24T19:28:21.930401Z","shell.execute_reply":"2024-02-24T19:28:21.929425Z","shell.execute_reply.started":"2024-02-24T19:28:21.895337Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","data = [\n"," {'Step': 0,\n","  'Variant': 'YES',\n","  'Action': 'Heavy rain has started',\n","  'Question': 'Go forward or back home?',\n","  'ToStep': 1,\n","  'UserGame': False},\n"," {'Step': 0,\n","  'Variant': 'NO',\n","  'Action': 'Say something with variant of \"Thank you, goodbye\".',\n","  'Question': 'Maybe another time?',\n","  'ToStep': 5,\n","  'UserGame': False},\n"," {'Step': 0,\n","  'Variant': 'RPT',\n","  'Action': 'Profound misunderstanding',\n","  'Question': 'Do you want to continue?',\n","  'ToStep': 0,\n","  'UserGame': True},\n"," {'Step': 1,\n","  'Variant': 'FORWARD',\n","  'Action': 'to right way rabbit, to left way turtle',\n","  'Question': 'Go right or go left?',\n","  'ToStep': 2,\n","  'UserGame': False},\n"," {'Step': 1,\n","  'Variant': 'BACK',\n","  'Action': 'home umbrella',\n","  'Question': 'Go or stay?',\n","  'ToStep': 4,\n","  'UserGame': False},\n"," {'Step': 1,\n","  'Variant': 'RPT',\n","  'Action': 'cold thunder',\n","  'Question': 'Where?',\n","  'ToStep': 1,\n","  'UserGame': True},\n"," {'Step': 2,\n","  'Variant': 'RIGHT',\n","  'Action': 'rabbit carrot big house',\n","  'Question': 'How are you feeling?',\n","  'ToStep': 3,\n","  'UserGame': False},\n"," {'Step': 2,\n","  'Variant': 'LEFT',\n","  'Action': 'turtle lake small house',\n","  'Question': 'How are you feeling?',\n","  'ToStep': 3,\n","  'UserGame': False},\n"," {'Step': 2,\n","  'Variant': 'RPT',\n","  'Action': 'rabit with honey or turtle with jam?',\n","  'Question': 'rabbit or turtle?',\n","  'ToStep': 2,\n","  'UserGame': True},\n"," {'Step': 3,\n","  'Variant': 'HAPPY',\n","  'Action': 'We are very glad to make you fun see you next time',\n","  'Question': 'Want try again?',\n","  'ToStep': 5,\n","  'UserGame': False},\n"," {'Step': 3,\n","  'Variant': 'SAD',\n","  'Action': 'home see many friends and fun',\n","  'Question': 'Stay with us or go away?',\n","  'ToStep': 4,\n","  'UserGame': False},\n"," {'Step': 3,\n","  'Variant': 'RPT',\n","  'Action': 'snake bubble',\n","  'Question': 'How are you feeling?',\n","  'ToStep': 3,\n","  'UserGame': True},\n"," {'Step': 4,\n","  'Variant': 'GO',\n","  'Action': 'to right way rabbit, to left way turtle',\n","  'Question': 'Go right or go left?',\n","  'ToStep': 2,\n","  'UserGame': False},\n"," {'Step': 4,\n","  'Variant': 'STAY',\n","  'Action': 'more friends and fun',\n","  'Question': 'Can we see you again?',\n","  'ToStep': 5,\n","  'UserGame': False},\n"," {'Step': 4,\n","  'Variant': 'RPT',\n","  'Action': 'something beatyfull',\n","  'Question': 'Go or stay?',\n","  'ToStep': 4,\n","  'UserGame': True},\n"," {'Step': 5,\n","  'Variant': 'START',\n","  'Action': 'Траля-ля и Труля-ля. Смотреть ниже',\n","  'Question': 'Hello!',\n","  'ToStep': 0,\n","  'UserGame': False},\n","]\n","\n","df = pd.DataFrame(data)\n","df"]},{"cell_type":"markdown","metadata":{},"source":["## Начальная сцена"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:10.411423Z","iopub.status.busy":"2024-02-24T19:29:10.410684Z","iopub.status.idle":"2024-02-24T19:29:10.415778Z","shell.execute_reply":"2024-02-24T19:29:10.414734Z","shell.execute_reply.started":"2024-02-24T19:29:10.411390Z"},"trusted":true},"outputs":[],"source":["start_scene = f'''\n","    Write a fairy tail, consisting of 4-5 sentences, using next instruction:\n","\n","    1. Use the characters and the environment below:\n","    ## Bear Boris, deep forest ##\n","\n","    2. Add in story next:\n","    ## Birds ##\n","\n","    3. Use in story next descriptions:\n","    ## very hungry ##\n","\n","    4. Finish story with question:\n","    ## Do you want to continue? ##\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["# Функции"]},{"cell_type":"markdown","metadata":{},"source":["## Стартовые параметры"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:13.841620Z","iopub.status.busy":"2024-02-24T19:29:13.840956Z","iopub.status.idle":"2024-02-24T19:29:13.846260Z","shell.execute_reply":"2024-02-24T19:29:13.845192Z","shell.execute_reply.started":"2024-02-24T19:29:13.841580Z"},"trusted":true},"outputs":[],"source":["# Счетчики Шагов и Пользовательских Игр\n","step_count = 5 # не менять, так надо\n","user_count = 0\n","\n","# Для хранения текущей Сцены\n","step_result = []"]},{"cell_type":"markdown","metadata":{},"source":["## Функция проверки начала квеста"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:17.302215Z","iopub.status.busy":"2024-02-24T19:29:17.301583Z","iopub.status.idle":"2024-02-24T19:29:17.307115Z","shell.execute_reply":"2024-02-24T19:29:17.306301Z","shell.execute_reply.started":"2024-02-24T19:29:17.302181Z"},"trusted":true},"outputs":[],"source":["def start():\n","    global step_count, user_count\n","    \n","    if step_count == 5:\n","        step_count = 0\n","        user_count = 0\n","        \n","        return True\n","    \n","    else:\n","        return False"]},{"cell_type":"markdown","metadata":{},"source":["## Функция для обработки шага и пользовательской игры"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:20.032310Z","iopub.status.busy":"2024-02-24T19:29:20.031714Z","iopub.status.idle":"2024-02-24T19:29:20.037857Z","shell.execute_reply":"2024-02-24T19:29:20.036872Z","shell.execute_reply.started":"2024-02-24T19:29:20.032277Z"},"trusted":true},"outputs":[],"source":["def quest_counter(to_step, user_game):\n","    global step_count\n","    global user_count\n","    \n","    # Меняем номер следующего шага\n","    step_count = to_step\n","    \n","    # Обработка в зависимости от значения user_count и to_step\n","    if user_count != 0 and to_step == step_count:\n","        user_count = 0\n","        step_count += 1\n","    elif user_count != 0 and to_step != step_count:\n","        user_count = 0\n","    \n","    # Включения счетчика в случае UserGame\n","    if user_game:\n","        user_count += 1"]},{"cell_type":"markdown","metadata":{},"source":["## Функция создание подготовленного промпта"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:23.415598Z","iopub.status.busy":"2024-02-24T19:29:23.414975Z","iopub.status.idle":"2024-02-24T19:29:23.420775Z","shell.execute_reply":"2024-02-24T19:29:23.419821Z","shell.execute_reply.started":"2024-02-24T19:29:23.415557Z"},"trusted":true},"outputs":[],"source":["def use_prompt_template(action, query, question):\n","    # Суммаризация прошлой сцены\n","    last_step = summary(step_result)[0]['summary_text']\n","    \n","    step_prompt = f'''\n","    Write a compelling continuation for the story, crafting 4-5 sentences based on the following guidelines:\n","\n","    1. Utilize the characters and surroundings introduced in the current narrative:\n","    ## {last_step} ##\n","\n","    2. Integrate the storyline with the following action:\n","    ## {action} ##\n","\n","    3. Incorporate vivid descriptions into the narrative, utilizing the provided details:\n","    ## {query} ##\n","\n","    4. Conclude the story by introducing a thought-provoking question:\n","    ## {question} ##\n","    '''\n","    return step_prompt"]},{"cell_type":"markdown","metadata":{},"source":["## Функция для обработки сценария и пользовательского ввода"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:26.254774Z","iopub.status.busy":"2024-02-24T19:29:26.254068Z","iopub.status.idle":"2024-02-24T19:29:26.263732Z","shell.execute_reply":"2024-02-24T19:29:26.262612Z","shell.execute_reply.started":"2024-02-24T19:29:26.254740Z"},"trusted":true},"outputs":[],"source":["def modify_query(query):\n","    # Проверяем на Начало\n","    if start():\n","        modified_query = start_scene\n","\n","        return modified_query\n","    \n","    else:\n","        # Фильтруем DataFrame по текущему шагу\n","        step_df = df[df.Step == step_count]\n","        \n","        # Проверяем запрос пользователя с помощью модели классификации\n","        desired_value = classify(query)[0]['label']\n","        print('Class: 'classify(query)[0], end='\\n\\n') # Для тестирования\n","        \n","        # Ищем подходящий Вариант\n","        if desired_value in step_df.Variant.unique():\n","            selected_row = step_df[step_df.Variant == desired_value]\n","            \n","            # Присваиваем значения для варианта\n","            action = selected_row.Action.values[0]\n","            question = selected_row.Question.values[0]\n","            to_step = selected_row.ToStep.values[0]\n","            user_game = selected_row.UserGame.values[0]\n","            \n","        else: # Запускаем повтор для уточнения\n","            selected_row = step_df[step_df.Variant == 'RPT']\n","            \n","            # Присваиваем значения для повтора\n","            action = selected_row.Action.values[0]\n","            question = selected_row.Question.values[0]\n","            to_step = selected_row.ToStep.values[0]\n","            user_game = selected_row.UserGame.values[0]\n","            \n","    # Изменяем запрос с помощью функции создания промпта\n","    modified_query = use_prompt_template(action, query, question)\n","    \n","    # Меняем шаги с помощью функции обработки шагов\n","    quest_counter(to_step, user_game)\n","    \n","    print('Query:---------------', modified_query, end='\\n') # Для тестирования\n","        \n","    return modified_query"]},{"cell_type":"markdown","metadata":{},"source":["## Функция для запроса и ответа модели"]},{"cell_type":"markdown","metadata":{},"source":["### Пример запроса-ответа"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:29:33.963665Z","iopub.status.busy":"2024-02-24T19:29:33.962651Z","iopub.status.idle":"2024-02-24T19:29:33.969336Z","shell.execute_reply":"2024-02-24T19:29:33.968225Z","shell.execute_reply.started":"2024-02-24T19:29:33.963629Z"},"trusted":true},"outputs":[],"source":["sample_instruction = '''\n","    Write a compelling continuation for the story, crafting 4-5 sentences based on the following guidelines:\n","\n","    1. Utilize the characters and surroundings introduced in the current narrative:\n","    ## In a cozy people's house, there lived a clever mouse named Mikey. One day, Mikey encountered a mischievous cat named Tom. Instead of the expected chase, they engaged in a series of funny games between them, surprising everyone with their unexpected friendship. The people in the house couldn't help but smile at the playful antics of the unlikely duo. As the sun set, casting a warm glow over the scene, a question lingered in the air, \"Do you want to continue witnessing the amusing adventures of Mikey and Tom?\" ##\n","\n","    2. Integrate the storyline with the following action:\n","    ## Dog Charlie in the garden ##\n","\n","    3. Incorporate vivid descriptions into the narrative, utilizing the provided details:\n","    ## go right ##\n","\n","    4. Conclude the story by introducing a thought-provoking question:\n","    ## Do you Happy? ##\n","'''\n","\n","sample_story = '''\n","    As the sun dipped below the horizon, casting a warm glow over the cozy people's house, Mikey and Tom found themselves facing a new adventure in the garden. Intrigued by the sudden appearance of Dog Charlie, they decided to go right, embarking on a journey filled with laughter and surprises. In the garden, the trio encountered colorful flowers, playful butterflies, and hidden pathways. The unlikely friendship between Mikey, Tom, and Charlie flourished amidst the beauty of nature. Now, as their delightful journey unfolded, a thought-provoking question hung in the air, \"Do you Happy?\" — a sentiment echoed by the joyous trio exploring the enchanting garden together.\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T19:49:39.726488Z","iopub.status.busy":"2024-02-24T19:49:39.726096Z","iopub.status.idle":"2024-02-24T19:49:39.734603Z","shell.execute_reply":"2024-02-24T19:49:39.733477Z","shell.execute_reply.started":"2024-02-24T19:49:39.726458Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def generate_response(query):\n","    global step_result\n","    \n","    messages = [\n","        {\"role\": \"user\", \"content\": sample_instruction},\n","        {\"role\": \"assistant\", \"content\": sample_story},\n","        {\"role\": \"user\", \"content\": modify_query(query)},\n","    ]\n","    \n","    #messages = [{\"role\": \"user\", \"content\": modify_query(query, df)}]\n","    #prompt_text = f\"<s>[INST]{sample_question}[/INST]{sample_answer}</s>[INST]{query}[/INST]\"\n","    \n","    #input_encoding = tokenizer.encode_plus(prompt_text, return_tensors=\"pt\")['input_ids'].to(device)\n","    input_encoding = tokenizer.apply_chat_template(messages, return_tensors=\"pt\").to(device)\n","\n","    generated_ids = model.generate(input_encoding,\n","                                   pad_token_id=tokenizer.eos_token_id,\n","                                   max_new_tokens=1000,\n","                                   do_sample=True)\n","\n","    decoded_response = tokenizer.batch_decode(generated_ids,\n","                                              skip_special_tokens=True)\n","\n","    # Обрезаем полный ответ, оставляем только сгенерированную историю\n","    step_result = re.sub(r'.*\\[\\/INST\\]\\n   ', '', decoded_response[0], flags=re.DOTALL)\n","        \n","    # Для тестирования\n","    print('-------------------', end='\\n')\n","    print('To Step>>: ', step_count)\n","    print('User Game: ', user_count, end='\\n\\n')\n","    print(\"Story:-----------------\", end='\\n\\n')\n","\n","    return step_result"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Пример использования\n","query = \"right\"\n","desired_value = 'NO'\n","modified_query = modify_query(query, df)\n","\n","print(\"Modified Query:\", modified_query)\n","print(\"Step_count:\", step_count)\n","print(\"User_count:\", user_count)"]},{"cell_type":"markdown","metadata":{},"source":["# Тестирование"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-24T22:17:18.886021Z","iopub.status.busy":"2024-02-24T22:17:18.885660Z","iopub.status.idle":"2024-02-24T22:17:37.101729Z","shell.execute_reply":"2024-02-24T22:17:37.100793Z","shell.execute_reply.started":"2024-02-24T22:17:18.885990Z"},"trusted":true},"outputs":[],"source":["# Для Начала любое значение, дальше отвечать на вопросы как захочется\n","message_answer = 'smiling'\n","\n","print('Current Step>>: ', step_count, end='\\n')\n","      \n","# print(generate_response(message_answer))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Для быстрого сброса или установки нужных шагов\n","\n","# step_count = 5\n","# user_count = 0\n","# step_count, user_count\n","\n","# Для быстрой проверки или замены\n","\n","#step_result = \"\"\"\"\"\"\n","# step_result\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gradio as gr\n","\n","def response(message, history):\n","    return generate_response(message)\n","\n","gr.ChatInterface(response).launch()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q -U datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from datasets import Dataset\n","\n","ds = Dataset.from_pandas(df)\n","ds[2]['Step'] = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ds[2]['Step'] = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df1 = ds.to_pandas()\n","df1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ds[2]['Step']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ds.save_to_disk('/kaggle/working/')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","from kaggle_secrets import UserSecretsClient\n","\n","access_token_read = UserSecretsClient().get_secret(\"HF_TOKEN\")\n","login(token = access_token_read)"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"modelInstanceId":3900,"sourceId":5112,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
